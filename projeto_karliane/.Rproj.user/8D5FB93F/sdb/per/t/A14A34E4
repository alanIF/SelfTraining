{
    "collab_server" : "",
    "contents" : "#PROBLEMAS A RESOLVER\n#karliane - tentar pegar os resultados (acuracia) - ver base teste script alexandre\n#alan - aprender como colocar os resultados em uma matriz e depois em um arquivo\n#alan - incluir as demais bases nesse script\n#karliane e alan - aprender a usar outros classificadores que n?o seja arvore\n#dividir a base em treinamento e teste, o q eu fiz n?o t? certo.\n#1 - transformar os atributos n?o num?ricos em num?ricos - tentar filtro weka - alan achou paleativo, usaremos de acordo com a necessidade\n#2 - descobrir pq a confian?a da iris s? d? 1 - resolvido, n?o sei como...\n\n#bases de dados\n#bupa, cleveland, ecoli, glass, haberman, iris, monk, pima, vehide, wisconsin\n#diret?rio local para salvar as bases e resultados\nsetwd(\"C:\\\\local_R\")\n\nprint(\"instala??o dos pacotes\")\n\n#pacote que inclui: data splitting, pre-processing, feature selection, model tuning using resampling, variable importance estimation\n#install.packages(\"caret\")\n#install.packages(\"caret\", dependencies = c(\"Depends\", \"Suggests\"))\n#pacote que inclui self-training e outros algoritmos de aprendizado semisupervisionado\n#install.packages(\"ssc\")\n#install.packages(\"DMwR\")\n#install.packages(\"caTools\")\n#install.packages(\"RWeka\")\n\nprint(\"carregar os pacotes\")\nlibrary(\"caret\") #parece n?o ser necess?rio\nlibrary(\"ssc\") #esse ? obrigat?rio\nlibrary(\"plyr\") #pacote q tem a fun??o join_all\nlibrary(\"RWeka\")\n\n#USANDO A FUN??O SELFTRAIN (USADA POR ALEXANDRE)\n\nlibrary(\"DMwR2\")\nlibrary(\"DMwR\")\nlibrary(\"datasets\")\n\nprint(\"Fun??o para pegar a base de dados e colocar em uma vari?vel base\")\ngetdata <- function(...)\n{\n    e <- new.env()\n    name <- data(..., envir = e)[1]\n    e[[name]]\n}\n\n#variaveis para guardar e gravar no arquivo\nit_g <-c() \nbd_g <-c()\nthrConf_g<-c()\nnr_added_exs_g<-c()\n\nfor (i in 1:6){\n\n  print(\"organizando os dados\")\n\n  if (i==1) {\n    #base de dados IRIS\n    base_original <- getdata(\"iris\")\n    classe <- \"Species\"\n  }else if (i==2){\n    #base de dados ECOLI\n    base_original <- read.arff(\"ecoli.arff\")\n    classe <- \"class\"\n  }\n  else if(i==3){\n    base_original <- read.arff(\"bupa.arff\");\n    classe <- \"selector\"\n    \n  }\n  else if(i==4){\n    base_original <- read.arff(\"glass.arff\")\n    classe <- \"Type\"\n    \n  }\n  else if(i==5){\n    base_original <- read.arff(\"haberman.arff\")\n    classe <-\"Survival_status\"\n  }\n  else if(i==6){\n    base_original <-read.arff(\"pima.arff\")\n    classe <- \"class\"\n    \n  }\n  else if(i==7){\n    base_original <-read.arff(\"cleveland.arff\")\n    classe <- \"num\"\n    \n  }\n  #tentando usar filtro do weka para transformar dados nominais em binarios\n  #nombi <- make_Weka_filter(\"weka/filters/supervised/attribute/NominalToBinary\") # creates an R interface to the WEKA filter\n  #datbin <- nombi(AT1 ~., data=base, control =Weka_control(N=TRUE, A=TRUE)) # Fehlermeldung\n  #datbin\n  \n\n#N?O EST? CERTO ASSIM, POIS ALGUNS EXEMPLOS N?O EST?O SENDO USADOS NO TREINAMENTO NUNCA E OUTROS EST?O APARECENDO MAIS DE UMA VEZ\n  set.seed(100)\n  if (i==1){\n    indice_treinamento <- createDataPartition(base_original$Species, p=0.75, list=FALSE)\n  }else if (i==2){\n    indice_treinamento <- createDataPartition(base_original$class, p=0.75, list=FALSE)\n  }\n    base <- base_original[indice_treinamento,]\n    base_teste <- base_original[-indice_treinamento,]\n    #PRECISO RENUMERAR OS INDICES, TANTO DE TREINAMENTO QUANTO DE TESTE\n  \n  \n  set.seed(214)# garante que o conjunto de dados escolhido para treinamento ser? sempre o mesmo - n?o sei se preciso dessa garantia\n  \n  #Quantidade de Exemplos\n  exemplos = nrow(base)\n  \n  #taxa inicial de exemplos rotulados erm percentual\n  taxa = 10\n  taxa_inicial = exemplos*taxa/100\n  \n  \n\n\n#sorteio de ids para treinamento\n  ids_treino_rot <- sample(exemplos,taxa_inicial, replace=FALSE)\n  \n\n  #base de treinamento\n  base_treino_rot <- base[ids_treino_rot,]\n  base_treino_sem_rot <- base[-ids_treino_rot,]\n\n\n  if (i==1) base_treino_sem_rot$Species <- NA #para base IRIS\n  else if (i==2) base_treino_sem_rot$class <- NA #para base ECOLI\n  else if(i==3)  base_treino_sem_rot$selector <- NA # para base BUPA\n  else if(i==4)   base_treino_sem_rot$Type <- NA # para base glass\n  else if(i==5) base_treino_sem_rot$Survival_status<- NA # para base haberman\n  else if (i==6) base_treino_sem_rot$class <- NA #para base pima\n  else if (i==7) base_treino_sem_rot$num <- NA #para base cleveland\n  \n  #base de treinamento rotulada\n  base_treino_self_training_rot <- base_treino_rot\n  base_treino_self_training_sem_rot <- base_treino_sem_rot\n  dfs <- list(base_treino_self_training_rot, base_treino_self_training_sem_rot)\n  base_treino_self_training <- join_all(dfs, type=\"full\")\n  \n  print(\"iniciando o treinamento\")\n  #fun??o que ser? passada como par?metro predFunc da fun??o selftrain\n  f <- function(m,d) {\n  \tl <- predict(m,d,type='class')\n  \tc <- apply(predict(m,d),1,max)\n  \tdata.frame(cl=l,p=c)\n  }\n  \n  #setando parametros do selftrain\n  \n  #classes da base de dados\n  if (i==1) form <- Species~.  \t#para base IRIS\t\t  #OU form <- basetreinoselftraining$Species\n  if (i==2) form <- class~.      #para base ECOLI\n  if(i==3) form <- selector~.    #para base puma\n  if(i==4)form <- Type~. # para base glass\n  if(i==5)form <- Survival_status~.# base haberman\n  if (i==6) form <- class~.      #para base pima\n  if(i==7) form <- num~. # para base cleveland\n  data <- base_treino_self_training\t#base de dados\n  learn <- learner('rpartXse',list(se=0.5))\n  predFunc <- 'f'   \t\t\t#Uma string com o nome de uma fun??o que ir? realizar as tarefas de classifica??o probabil?stica que ser?o necess?rias durante o processo de self-training\n  thrConf=0.9       \t\t\t#taxa de confian?a dos exemplos a serem incluidos no conjunto de rotulados\n  maxIts=10\t\t\t\t\t#n?mero m?ximo de itera??es\n  percFull=1\t\t\t\t\t#Um n?mero entre 0 e 1. Se a porcentagem de exemplos rotulados atingir esse valor o processo de self-training ? parado\n  verbose=TRUE\t\t\t\t#Um booleano indicando o n?vel de verbosidade?? (verbosity??) da fun??o\n  \n  #adapta??o da implementa??o do selftrain\n  data\n  N <- NROW(data)\n  it <- 0\n  \n  \n  soma_Conf <- 0\n  qtd_Exemplos_Rot <- 0\n  totalrot <- 0\n  \n  sup <- which(!is.na(data[,as.character(form[[2]])])) #sup recebe o indice de todos os exemplos rotulados\n      repeat {\n        \n        it <- it+1\n  \t\n\n      \tif (it>1) thrConf <- (thrConf + (soma_Conf/qtd_Exemplos_Rot) + (qtd_Exemplos_Rot/N))/3\n      \tsoma_Conf <- 0\n      \tqtd_Exemplos_Rot <- 0\n#      \tcat('zerou variaveis', '\\t limiar confian?a(thrConf).',thrConf,'\\n soma Confian?a rotulados. =',soma_Conf , '\\n quantidade rotulados. =',qtd_Exemplos_Rot,'\\n')\n      \n  \n        model <- runLearner(learn,form,data[sup,])\n        probPreds <- do.call(predFunc,list(model,data[-sup,]))\n  \n\n        new <- which(probPreds[,2] > thrConf)\n  \t\n\n  \n        \n\n        if (verbose) {\n            cat('IT.',it,'BD',i,thrConf,'\\t nr. added exs. =',length(new),'\\n') \n            ##guardando nas variaveis \n            it_g <-c(it_g,it)\n            bd_g <-c(bd_g,i)\n            thrConf_g<-c(thrConf_g,thrConf)\n            nr_added_exs_g<-c(nr_added_exs_g,length(new))\n            ##resultado <-  c(it,\",\",i,\",\",thrConf,\",\",length(new))\n            ##write(resultado, file = \"result\")\n            \n          \n        }\n\n        \n        if (length(new)) {\n          data[(1:N)[-sup][new],as.character(form[[2]])] <- as.character(probPreds[new,1])\n  \n  \t      soma_Conf <- sum(soma_Conf, probPreds[new,2])\n  \t      qtd_Exemplos_Rot <- length(data[(1:N)[-sup][new],as.character(form[[2]])])\n  \t      totalrot <- totalrot + qtd_Exemplos_Rot\n#   \t      cat('dentro do self training', '\\n limiar confian?a(thrConf).',thrConf,'\\n soma Confian?a rotulados. =',soma_Conf, '\\n quantidade rotulados. =',qtd_Exemplos_Rot,'\\n','\\n total rotulados. =',totalrot,'\\n')\n  \n          sup <- c(sup,(1:N)[-sup][new])\n        } else break\n        if (it == maxIts || length(sup)/N >= percFull) break\n      }\n  \n#matriz de confusao do selftraining\n#N?O EST? FUNCIONANDO PARA BASE DE DADOS 2, A MATRIZ N?O APARECE COM A MESMA QUANTIDADE DE LINHAS E COLUNAS  \n    if (i==1){\n      matriz_confusao1 = table(predict(model,base_teste,type='class'),base_teste$Species)\n      n <- length(base_teste$Species)\n  }\n  else if (i==2){\n    matriz_confusao1 = table(predict(model,base_teste,type='class'),base_teste$class)\n    n <- length(base_teste$class)\n  }\n  #matriz_confusao1\n  if (i==1)\n    cat(\"\\n Acerto (%) = \\n\", levels(base_original[, \"Species\"]), \"\\n\", diag(matriz_confusao1) / colSums(matriz_confusao1) * 100)\n  else if (i==2)\n    cat(\"\\n Acerto (%) = \\n\", levels(base_original[, \"class\"]), \"\\n\", diag(matriz_confusao1) / colSums(matriz_confusao1) * 100)\n\n  cat(\"\\n Acerto global (%) =\", sum(diag(matriz_confusao1)) / n * 100)\n  \n  \n#  data\n  #predicted predict(model, newdata = base_teste)\n  cat('FIM', '\\t base de dados ', i, '\\n', 'total rotulados: ', totalrot, '\\n')\n}\n#data frame que sera guardado no arquivo\ndata_arquivo <- data.frame(it_g,bd_g,thrConf_g,nr_added_exs_g)\n#escrever no arquivo\nwrite.csv(data_arquivo, \"resultado.csv\", row.names = FALSE)\n",
    "created" : 1496945648509.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1548962765",
    "id" : "A14A34E4",
    "lastKnownWriteTime" : 1496855872,
    "last_content_update" : 1496855872,
    "path" : "C:/local_R/projeto_karliane/experimentos_karliane_implementando_self_train.R",
    "project_path" : "experimentos_karliane_implementando_self_train.R",
    "properties" : {
    },
    "relative_order" : 5,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}